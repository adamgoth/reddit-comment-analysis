{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is import the requests library. This is what we\n",
    "will use to make the HTTP request to reddit to get the comment data from the\n",
    "reddit post. After that, we will initialize a few global variables. We will use\n",
    "these global variables to keep track of data as we parse through comments.\n",
    "`comment_count` is an integer and will track the number of comments we parse,\n",
    "`comment_array` is an array and will hold the actual comment strings, and\n",
    "`more_comment_ids` is another array that will hold ID strings that we will need\n",
    "in order to fetch additional comments that are not returned in the initial\n",
    "payload (commonly found in posts with many comments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests  # The requests library for HTTP requests in Python\n",
    "\n",
    "# globals\n",
    "comment_count = 0\n",
    "comment_array = []\n",
    "more_comment_ids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to fetch the data for the reddit post. To do that, we can append\n",
    "`.json` to the end of any reddit post URL.\n",
    "\n",
    "An example would be:\n",
    "`https://www.reddit.com/r/redditdev/comments/krolrb/multicomments.json`.\n",
    "\n",
    "What we get back is JSON that will have a basic format that looks like this:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"kind\": \"Listing\",\n",
    "    \"data\": {\n",
    "        \"children\": [\n",
    "            \"kind\": \"t1\",\n",
    "            \"data\": {\n",
    "                \"body\": \"\",\n",
    "                \"replies\": \"\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "A reddit post is referred to as a\n",
    "\"[Listing](https://www.reddit.com/dev/api/#listings)\". Listings can contain many\n",
    "kinds of children. A child with a `kind` of `t1` indicates that the child\n",
    "represents a comment. Within the comments `data` property, among many other\n",
    "properties, the text of the comment can be found on the `body` property, along\n",
    "with any possible replies which are located on the `replies` property. Replies\n",
    "are structured the same way as comments. They contain children and the children\n",
    "has `kind` and `data` properties. Within every reply to a comment, we may see\n",
    "another reply to that reply comment. Each of these contains their own\n",
    "identically formatted children. So in order to analyze all comments within a\n",
    "thread, we'll have to recursively sift through all comments and replies.\n",
    "\n",
    "If having to follow each individual comment tree recursively to its end wasn't\n",
    "tricky enough, there's another issue we have to worry about. Since comment\n",
    "threads can become quite long, not every comment is always displayed on the\n",
    "initial thread load. When this happens, reddit shows \"load more replies\" buttons\n",
    "within threads. So how do we get these as well? To handle these instances, the\n",
    "API will deliver a child with a `kind` property value of `more`.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"kind\": \"more\",\n",
    "    \"data\": {\n",
    "        \"count\": 2,\n",
    "        \"name\": \"t1_ghp1m6v\",\n",
    "        \"id\": \"ghp1m6v\",\n",
    "        \"parent_id\": \"t1_ghozojl\",\n",
    "        \"depth\": 2,\n",
    "        \"children\": [\n",
    "            \"ghp1m6v\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "The array of `children` within the `more` object will contain a list of thread\n",
    "IDs that can be used to fetch additional comments. In the code example above,\n",
    "there is just one child ID, `ghp1m6v`. So in addition to parsing all comment\n",
    "trees recursively, we will also have to collect any additional comment thread\n",
    "IDs and then do the same thing for those.\n",
    "\n",
    "Hopefully, you are still with me at this point. Talking about all of this\n",
    "without writing any code can be confusing, so let's try to break it down with\n",
    "some functions that will help us achieve this goal.\n",
    "\n",
    "The first function we'll write is `parse_children_for_comments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_children_for_comments(children):\n",
    "    global comment_count\n",
    "    global comment_array\n",
    "    for child in children:\n",
    "        if child['kind'] == \"more\":\n",
    "            children = child['data']['children']\n",
    "            for id in children:\n",
    "                more_comment_ids.append(id)\n",
    "        if child['kind'] == \"t1\":\n",
    "            comment_count += 1\n",
    "            comment_array.append(child['data']['body'])\n",
    "            get_replies(child['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will take an array of `children` objects that are sent back in the response\n",
    "data and will pull out the comment text which is found in the `body` property.\n",
    "For each child in the array argument of `children`, we will check its `kind`. If\n",
    "the `kind` is `more`, we will loop through and add each id to the global array\n",
    "we created, `more_comment_ids`. We will eventually come back to this array of\n",
    "ids and parse through it.\n",
    "\n",
    "Next, if the `kind` is `t1`, that means we have a comment and we want to read\n",
    "its text. In order to do that, we simply get the text with\n",
    "`child['data']['body']` and append it to our global `comment_array` variable.\n",
    "\n",
    "After appending the comment to the `comment_array`, we need to check if there\n",
    "are any replies to that comment. Since we will be doing this check many times,\n",
    "it's best that we write a helper function for it. We'll call it `get_replies`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_replies(comment):\n",
    "    global comment_count\n",
    "    if comment['replies'] != \"\":\n",
    "        children = comment['replies']['data']['children']\n",
    "        parse_children_for_comments(children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we check if there are any replies. When there are no replies, the\n",
    "`replies` property will be an empty string. If the string is not empty, we know\n",
    "we have a reply. As I mentioned above, replies take the same format as the\n",
    "original comment it is replying to. So in order to parse the reply text, we can\n",
    "reuse the same `parse_children_for_comments` function we already wrote. Since\n",
    "`parse_children_for_comments` will again call `get_replies`, and `get_replies`\n",
    "will again call `parse_children_for_comments` until there are no comments left,\n",
    "this will recursively continue until we reach a child comment with an empty\n",
    "`replies` property. Pretty neat.\n",
    "\n",
    "With those helper functions defined, we're ready to fetch our data. In order to\n",
    "do this, we will use a built-in Python function called\n",
    "[`input`](https://docs.python.org/3/library/functions.html#input) which will\n",
    "allow the user to enter a URL to a reddit post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the reddit post url (e.g. https://www.reddit.com/r/redditdev/comments/krolrb/multicomments/):\n",
      "https://www.reddit.com/r/redditdev/comments/krolrb/multicomments/\n"
     ]
    }
   ],
   "source": [
    "# get url from user\n",
    "print('enter the reddit post url (e.g. https://www.reddit.com/r/redditdev/comments/krolrb/multicomments/):')\n",
    "thread_url = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can expect the user to paste in a URL for a reddit post. For example, it may\n",
    "look something like this:\n",
    "`https://www.reddit.com/r/redditdev/comments/krolrb/multicomments/`\n",
    "\n",
    "To get the post data, we need to turn\n",
    "`https://www.reddit.com/r/redditdev/comments/krolrb/multicomments/` into\n",
    "`https://www.reddit.com/r/redditdev/comments/krolrb/multicomments.json`.\n",
    "\n",
    "To do that, we can write a small helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_input(url):\n",
    "    last_char = url[-1]\n",
    "    if last_char == '/':\n",
    "        url = url[:-1]\n",
    "    url = f'{url}.json'\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass the URL as an argument into the function. The function checks if the\n",
    "last character of `url` is a `/` and removes it if it is. Then the function\n",
    "appends `.json` to the end of `url`. After we pass the user's inputted URL to\n",
    "this function, we're ready to fetch the post data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass user's url to sanitize helper\n",
    "sanitized_thread_url = sanitize_input(thread_url)\n",
    "\n",
    "# make network call\n",
    "req_data = requests.get(sanitized_thread_url, headers={'User-agent': 'adamgoth.com'})\n",
    "\n",
    "if req_data.status_code != 200:\n",
    "    print('request failed')\n",
    "    print(req_data.json())\n",
    "\n",
    "if req_data.status_code == 200:\n",
    "    json_data = req_data.json()\n",
    "    for item in json_data:\n",
    "        children = item['data']['children']\n",
    "        parse_children_for_comments(children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call `requests.get()`, passing our URL as the first parameter, as well as a\n",
    "headers value for a second parameter. The reason we need to specify a\n",
    "`User-agent` property in the header is so that we have a unique identity to\n",
    "reddit. This will ensure we appear entirely anonymous and run into\n",
    "[rate-limiting](https://en.wikipedia.org/wiki/Rate_limiting) issues.\n",
    "\n",
    "Once we have our data back in our `req_data` variable, the first thing we'll\n",
    "check is if we did not get a `200` response for any reason. If the response is\n",
    "not `200`, we will print out the error.\n",
    "\n",
    "Assuming we get a `200`, we can then start parsing the data. We can use the\n",
    "requests library built-in JSON decoder and called `.json()` on the response. We\n",
    "then write a simple `for` statement that takes each child in the response data\n",
    "and passes it to the `parse_children_for_comments` we previously discussed.\n",
    "\n",
    "After the `for` loop from line 13 completes, we should have a number of comments\n",
    "stored in our global `comment_array`. Additionally, depending on the number of\n",
    "comments from the post, we may have found some additional comment IDs and stored\n",
    "them in our global `more_comment_ids` array. As a reminder, these are IDs we can\n",
    "use to fetch more comments that did not appear in the initial load. In the\n",
    "reddit UI, these represent the links within comment threads that appear as \"load\n",
    "more replies\", and in our data response, these IDs come from the children that\n",
    "have a `kind` property value of `more`.\n",
    "\n",
    "The URL for fetching the additional comment data looks similar to the URL we\n",
    "used for fetching the initial post data. The only difference is the comment ID\n",
    "is appended to the end. So\n",
    "`https://www.reddit.com/r/redditdev/comments/krolrb/multicomments.json` becomes\n",
    "`https://www.reddit.com/r/redditdev/comments/krolrb/multicomments/{comment_id}.json`.\n",
    "We can write a simple helper function to do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_thread_url(comment_id):\n",
    "    return sanitized_thread_url.replace('.json', f'/{comment_id}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simply pass the `comment_id` as an argument and then do a string replace on\n",
    "`.json` with `/{comment_id}.json`.\n",
    "\n",
    "We're then ready to make the requests for the additional comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle extra comment ids\n",
    "for id in more_comment_ids:\n",
    "    req_data = requests.get(create_thread_url(\n",
    "        id), headers={'User-agent': 'adamgoth.com'})\n",
    "    if req_data.status_code != 200:\n",
    "        print('request failed')\n",
    "        print(req_data.json())\n",
    "\n",
    "    if req_data.status_code == 200:\n",
    "        json_data = req_data.json()\n",
    "        for item in json_data:\n",
    "            children = item['data']['children']\n",
    "            parse_children_for_comments(children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fetch the additional comments, we'll use another `for` loop to loop through\n",
    "each ID in the `more_comment_ids` array. For each one, we again use\n",
    "`requests.get()`, passing the comment ID to the `create_thread_url` function we\n",
    "just wrote, along with the same `User-agent` header as our previous request.\n",
    "Once we have our response, we again check the status code, and if it's\n",
    "successful, we'll parse the data the same way we did before, passing each child\n",
    "in the data to `parse_children_for_comments`. As a word of caution, for posts\n",
    "with thousands of comment replies, this can result in a large number of\n",
    "additional comment IDs. It's possible to have hundreds of IDs to fetch. Each one\n",
    "of these will require a synchronous network call, so it can take quite a while\n",
    "if this is the case.\n",
    "\n",
    "Once all the additional comment IDs have been fetched, we have all the data we\n",
    "need to run our word analysis. To do this, we will combine all of the comments\n",
    "in our global `comment_array` variable into a single string. We will then write\n",
    "a function which will parse that string and keep track of how many times each\n",
    "word appears. The function to do that looks like this:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
